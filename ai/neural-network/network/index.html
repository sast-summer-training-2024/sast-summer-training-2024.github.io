
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../../../basic/Web_basics/Web_basics.pdf">
      
      
        <link rel="next" href="../../dp-and-pytorch/readme/">
      
      
      <link rel="icon" href="../../../images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.0, mkdocs-material-9.5.29">
    
    
      
        <title>神经网络 - 酒井科协暑培 2024</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.76a95c52.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#_1" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="页眉">
    <a href="../../.." title="酒井科协暑培 2024" class="md-header__button md-logo" aria-label="酒井科协暑培 2024" data-md-component="logo">
      
  <img src="../../../images/logo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            酒井科协暑培 2024
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              神经网络
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3 3.19.09m3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95 2.06.05m-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31Z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5c-.84 0-1.65.15-2.39.42L12 2M3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29L3.34 7m.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14L3.36 17M20.65 7l-1.77 3.79a7.023 7.023 0 0 0-2.38-4.15l4.15.36m-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29L20.64 17M12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44L12 22Z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="查找">
        
        <button type="reset" class="md-search__icon md-icon" title="清空当前内容" aria-label="清空当前内容" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/sast-summer-training-2024/sast-summer-training-2024.github.io" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    SAST Summer Training 2024
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="标签" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../.." class="md-tabs__link">
          
  
    
  
  首页

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../basic/linux_git/Pre-requisite/" class="md-tabs__link">
          
  
    
  
  基础

        </a>
      </li>
    
  

    
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="./" class="md-tabs__link">
          
  
    
  
  AI

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="导航栏" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="酒井科协暑培 2024" class="md-nav__button md-logo" aria-label="酒井科协暑培 2024" data-md-component="logo">
      
  <img src="../../../images/logo.png" alt="logo">

    </a>
    酒井科协暑培 2024
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/sast-summer-training-2024/sast-summer-training-2024.github.io" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    SAST Summer Training 2024
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_1" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../.." class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    首页
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_1" id="__nav_1_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_1">
            <span class="md-nav__icon md-icon"></span>
            首页
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../links/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    资源链接
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    基础
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            基础
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1" >
        
          
          <label class="md-nav__link" for="__nav_2_1" id="__nav_2_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Linux & Git
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_1">
            <span class="md-nav__icon md-icon"></span>
            Linux & Git
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../basic/linux_git/Pre-requisite/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    课前准备
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../basic/linux_git/Linux/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Linux
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../basic/linux_git/Git/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Git
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_2" >
        
          
          <label class="md-nav__link" for="__nav_2_2" id="__nav_2_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Python
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_2">
            <span class="md-nav__icon md-icon"></span>
            Python
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../basic/python/Pre-requisite/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    课前准备
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../basic/python/handout/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    正文
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_3" >
        
          
          <label class="md-nav__link" for="__nav_2_3" id="__nav_2_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Web基础
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_3">
            <span class="md-nav__icon md-icon"></span>
            Web基础
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../无" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    课前准备
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../basic/Web_basics/Web_basics.pdf" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    课件
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
      
        
      
    
    
      
        
        
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            
  
  <span class="md-ellipsis">
    AI
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            AI
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    神经网络
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    神经网络
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    <span class="md-ellipsis">
      神经网络的简单定义
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    <span class="md-ellipsis">
      神经网络能够处理的问题
    </span>
  </a>
  
    <nav class="md-nav" aria-label="神经网络能够处理的问题">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    <span class="md-ellipsis">
      神经网络方法在人工智能领域的定位
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_5" class="md-nav__link">
    <span class="md-ellipsis">
      神经网络常用来处理什么样的问题
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_6" class="md-nav__link">
    <span class="md-ellipsis">
      神经网络的优点
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../dp-and-pytorch/readme/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    数据处理可视化与pytorch
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    <span class="md-ellipsis">
      神经网络的简单定义
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    <span class="md-ellipsis">
      神经网络能够处理的问题
    </span>
  </a>
  
    <nav class="md-nav" aria-label="神经网络能够处理的问题">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    <span class="md-ellipsis">
      神经网络方法在人工智能领域的定位
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_5" class="md-nav__link">
    <span class="md-ellipsis">
      神经网络常用来处理什么样的问题
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_6" class="md-nav__link">
    <span class="md-ellipsis">
      神经网络的优点
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
    
                  

  
  


<h1 id="_1">什么是神经网络<a class="headerlink" href="#_1" title="Permanent link">&para;</a></h1>
<h2 id="_2">神经网络的简单定义<a class="headerlink" href="#_2" title="Permanent link">&para;</a></h2>
<blockquote>
<p>神经网络是由 <strong>包含或不包含参数的简单处理单元</strong>相互连接构成的大规模结构。 它能够<strong>将数据经过由连接和参数决定的流程</strong>进行计算，将输入映射到输出。</p>
</blockquote>
<h2 id="_3">神经网络能够处理的问题<a class="headerlink" href="#_3" title="Permanent link">&para;</a></h2>
<h3 id="_4">神经网络方法在人工智能领域的定位<a class="headerlink" href="#_4" title="Permanent link">&para;</a></h3>
<blockquote>
<p>人工智能</p>
<blockquote>
<p>机器学习</p>
<blockquote>
<p>神经网络</p>
</blockquote>
</blockquote>
</blockquote>
<h3 id="_5">神经网络常用来处理什么样的问题<a class="headerlink" href="#_5" title="Permanent link">&para;</a></h3>
<ul>
<li>从数据中获取并保存信息（数据驱动任务）</li>
<li>拥有结构化的、相对大量的结构化输入-输出对数据</li>
<li>有明确、可计算的性能评估指标</li>
<li>常见的有分类、预测、生成任务</li>
</ul>
<h3 id="_6">神经网络的优点<a class="headerlink" href="#_6" title="Permanent link">&para;</a></h3>
<ul>
<li>可以形成拥有大规模参数的结构：信息提取和保存能力强，泛化性能好</li>
<li>可扩展性：结构化的输入和输出，便于扩展和复用</li>
<li>非线性：从输入特征空间到输出特征空间的映射是非线性的</li>
</ul>
<h1 id="_7">学习任务的组成<a class="headerlink" href="#_7" title="Permanent link">&para;</a></h1>
<h2 id="_8">学习任务<a class="headerlink" href="#_8" title="Permanent link">&para;</a></h2>
<blockquote>
<p>学习任务是由<strong>模型M、经验E、任务T、性能量度P</strong>组成的。模型的学习是指<strong>模型M通过得到经验E，在性能量度P意义下相对得到经验E并运行学习算法前在任务T上有所改进</strong>。</p>
</blockquote>
<p>对于神经网络而言，模型M即为神经网络本身，经验E为数据，性能量度P为损失函数，而任务T即为希望使用神经网络解决的机器学习问题。 </p>
<p>例如：神经网络模型的学习任务是指该神经网络在图像分类任务上进行学习，在获得标注后的图片分类数据并进行训练后，在分类准确率标准下相较于训练前有所提升。</p>
<p>在神经网络学习任务中，我们称使用数据作为经验E，对神经网络使用学习算法进行优化的过程为<strong>训练</strong></p>
<h2 id="_9">数据与经验<a class="headerlink" href="#_9" title="Permanent link">&para;</a></h2>
<p>对任务T进行数学建模：</p>
<blockquote>
<p>对于某个样本空间已知而概率未知的概率空间<span class="arithmatex"><span class="MathJax_Preview">(\Omega，\cal{F}，\mathbb{R})</span><script type="math/tex">(\Omega，\cal{F}，\mathbb{R})</script></span>，希望通过独立同分布的采样结果<span class="arithmatex"><span class="MathJax_Preview">{X_i}</span><script type="math/tex">{X_i}</script></span> ~ <span class="arithmatex"><span class="MathJax_Preview">\cal{P}(x)</span><script type="math/tex">\cal{P}(x)</script></span>  i.i.d 估计分布<span class="arithmatex"><span class="MathJax_Preview">\cal{P}</span><script type="math/tex">\cal{P}</script></span>。 我们称采样结果 <span class="arithmatex"><span class="MathJax_Preview">{X_i}</span><script type="math/tex">{X_i}</script></span> 为<strong>数据</strong></p>
</blockquote>
<p>从中可以得到几个数据驱动机器学习任务的经典假设：
1. 真实分布假设：认为数据符合某个确定的真实分布
2. 独立同分布假设：认为数据是从真实分布中独立同分布采样的
3. 低维流形假设：自然的原始数据是低维的流形嵌入于原始数据所在的高维空间（无法通过有限空间和时间估计无穷维样本空间上的概率分布）</p>
<h2 id="_10">损失函数与性能量度<a class="headerlink" href="#_10" title="Permanent link">&para;</a></h2>
<p>我们需要一个能够不需要人类参与的性能度量算法，以便神经网络自行迭代而无需人类的干预，从而显著提升效率。 </p>
<p>通常来说，性能量度P是特定于任务T而言的。 而由于人类经验的复杂性，我们通常只能够近似地评估模型的性能。 在神经网络学习任务中，性能量度P被称为损失函数：</p>
<h3 id="_11">损失函数<a class="headerlink" href="#_11" title="Permanent link">&para;</a></h3>
<blockquote>
<p>对于给定的模型M，和给定的经验E，损失函数定义为函数<span class="arithmatex"><span class="MathJax_Preview">cal(L):(M，E) -&gt; RR</span><script type="math/tex">cal(L):(M，E) -> RR</script></span>，#text(fill: purple.darken(10%))<strong>损失函数值越大，代表人类认为模型M在任务T上的表现与经验E的表现差距越大</strong></p>
</blockquote>
<p>比如，在图像分类任务中，<span class="arithmatex"><span class="MathJax_Preview">\cal{L}</span><script type="math/tex">\cal{L}</script></span>(M，E)可以为在某一组标注好类别图像数据上，模型在预测这组图像类别时的错误率。 </p>
<h3 id="_12">训练集与测试集<a class="headerlink" href="#_12" title="Permanent link">&para;</a></h3>
<p>在神经网络的评估中，一个重要的指标是其泛化能力，即对于在经验E没有涉及的、同时位于任务T的样本空间范围内的点的估计效果。 通常我们会从训练数据中单独分出一小部分，在训练时不作为样本对模型进行训练，并评估模型在这些样本上的性能。 我们称<strong>在训练时作为样本对模型进行训练的数据集合为数据集，分出来的那一小部分为测试集</strong>。 通常，为了得知模型在训练过程中的性能变化趋势，我们还会从测试集中分出一小部分作为<strong>验证集</strong>，在训练中途多次在验证集上测试模型的性能表现。 </p>
<h1 id="_13">神经网络的构成<a class="headerlink" href="#_13" title="Permanent link">&para;</a></h1>
<p>我们在第一节强调了神经网络构成的两个部分：带参数或不带参数的简单结构，以及它们的连接。 在本节中将详细说明这两部分。 </p>
<h2 id="_14">感知机<a class="headerlink" href="#_14" title="Permanent link">&para;</a></h2>
<p>线性感知机算法（PLA）1957 年由 Frank Rosenblatt 提出。 感知机是二分类的线性分类模型，其输入为实例的特征向量，输出为实例的类别，取值为+1和-1。 </p>
<blockquote>
<p><strong>perceptron</strong>: 
$$ f(\vec{x}) = s i g n(\vec{w}^T \vec{x} + b) $$，where <span class="arithmatex"><span class="MathJax_Preview">w，x \in \mathbb{R}^n，b \in \mathbb{R}</span><script type="math/tex">w，x \in \mathbb{R}^n，b \in \mathbb{R}</script></span></p>
</blockquote>
<p>显然，这是一个含参数<span class="arithmatex"><span class="MathJax_Preview">w</span><script type="math/tex">w</script></span>的，且能够将输入根据参数<span class="arithmatex"><span class="MathJax_Preview">w</span><script type="math/tex">w</script></span>唯一映射到输出的简单结构。 </p>
<p>感知机是神经网络中最常使用、最简单的含参结构。 虽然感知机只能进行简单的线性可分分类问题，但通过连接大量感知机，以及更换符号函数为其他非线性函数，我们可以构造出复杂的结构。 </p>
<h2 id="mlp">多层感知机MLP<a class="headerlink" href="#mlp" title="Permanent link">&para;</a></h2>
<p>多层感知机是通过感知机的拼接组成的结构。 它是最简单的神经网络结构。 这个结构在几乎所有的现代深度神经网络中都存在。 </p>
<blockquote>
<p><strong>multiple layer perceptron</strong>: 
$$ f(\vec{x}) = f_N \circ \cdots \circ f_0 $$
$$ f_i(\vec{x}) = \sigma(W \vec{x} + \vec{b}) $$
where <span class="arithmatex"><span class="MathJax_Preview">W \in \mathbb{R}^{n_i \times n_{i+1}}，b \in \mathbb{R}^n_{i+1}，i \in {0，\dots ，N}</span><script type="math/tex">W \in \mathbb{R}^{n_i \times n_{i+1}}，b \in \mathbb{R}^n_{i+1}，i \in {0，\dots ，N}</script></span></p>
</blockquote>
<p>其结构可以表示为：
<img alt="" src="../imgs/mlp.png" />
其中的<span class="arithmatex"><span class="MathJax_Preview">h_i、o_i</span><script type="math/tex">h_i、o_i</script></span>代表一个将符号函数替换为非线性激活函数的感知机。 （尝试根据图中给出的结构，推导上面给出的公式。 进一步的，写出<span class="arithmatex"><span class="MathJax_Preview">W_1，W_2</span><script type="math/tex">W_1，W_2</script></span>与各感知机参数之间的关系）</p>
<p>我们可以发现，<strong>仅通过连接感知机，我们就获得了一个可以任意增大规模而基础结构相同的，从任意维欧式空间向任意维欧式空间映射的结构。</strong> 注意到，由于引入了非线性激活函数（试想如果使用线性激活函数会怎样？），这个结构还可以表示非线性的映射。 于是我们获得了一个典型的神经网络模型。 </p>
<h1 id="_15">神经网络的学习算法<a class="headerlink" href="#_15" title="Permanent link">&para;</a></h1>
<h2 id="_16">神经网络的优化<a class="headerlink" href="#_16" title="Permanent link">&para;</a></h2>
<p>在第二节我们探讨了学习任务，并定义了神经网络中的性能量度——损失函数。 在上一节，我们获得了一个典型的神经网络模型。 在这一章，我们自然需要讨论如何通过使用经验E，即数据，使得神经网络在损失函数意义下获得性能提升。 </p>
<h2 id="_17">最小化损失函数<a class="headerlink" href="#_17" title="Permanent link">&para;</a></h2>
<p>注意到损失函数的定义，我们假定了模型性能越差，损失函数越大。 也就是说，<strong>我们只需要反过来通过调整M，在经验E上最小化损失函数，就能达到提高模型M在任务T上表现的目的。</strong> 于是，神经网络的优化任务可以如下形式化定义：</p>
<blockquote>
<div class="arithmatex">
<div class="MathJax_Preview"> \theta^* = \arg \min_\theta \cal{L} \text{(M}_\theta\text{,E)} </div>
<script type="math/tex; mode=display"> \theta^* = \arg \min_\theta \cal{L} \text{(M}_\theta\text{,E)} </script>
</div>
</blockquote>
<p>其中<span class="arithmatex"><span class="MathJax_Preview">\theta</span><script type="math/tex">\theta</script></span>是模型中<strong>所有的可调整参数</strong>。 通过损失函数，我们成功将主观的性能评估和改进问题，转化为了计算和优化损失函数的问题，进而可以通过数值方法解决。 可以认为，通过设计损失函数，我们将主观性转移至了损失函数中。 </p>
<h1 id="_18">基于梯度的优化方法<a class="headerlink" href="#_18" title="Permanent link">&para;</a></h1>
<p>在数值计算领域，优化问题的最常用、效果最好的算法绝大部分是基于梯度的算法。 由于神经网络的简单基本结构的可导性以及参数空间的连续性，我们可以方便地使用梯度法作为优化方法。</p>
<h2 id="_19">梯度下降算法<a class="headerlink" href="#_19" title="Permanent link">&para;</a></h2>
<p>基于梯度的优化方法中最易理解和实现的是梯度下降算法：</p>
<h1 id="block">block(<a class="headerlink" href="#block" title="Permanent link">&para;</a></h1>
<p>fill: luma(230),
  inset: 8pt,
  radius: 4pt,
)[令$ theta_(n+1) = theta_(n) - eta (partial cal(L)(M_theta_n，E))/(partial theta_n) $
则对于一类性质较好的<span class="arithmatex"><span class="MathJax_Preview">cal(L)</span><script type="math/tex">cal(L)</script></span>和<span class="arithmatex"><span class="MathJax_Preview">M_theta</span><script type="math/tex">M_theta</script></span>，我们有
$ lim_(eta arrow 0，n arrow infinity) theta_n = theta^* $
]
我们知道梯度的反向是该点邻域中函数值下降最快的方向，因此当函数不太差时，沿梯度的反向进行参数的更新都有机会达到函数的最小值。 </p>
<p>然而梯度下降算法有两个缺点。 首先，该方法对于函数的性质有要求，否则对于参数的初值较为敏感，容易陷入局部极小值。 (考虑有两个谷的函数)。 其次，该方法需要在全部样本上计算出梯度，并求平均。 这极大的降低了梯度下降的效率。 </p>
<h2 id="sgd">随机梯度下降算法(SGD)<a class="headerlink" href="#sgd" title="Permanent link">&para;</a></h2>
<p>随机梯度下降算法是目前几乎所有神经网络的学习算法。 目前已知的绝大多数算法都是基于这个方法的优化或微调。 或者说，今天我们所讲的神经网络就是指能够使用随机梯度下降算法进行训练的神经网络。</p>
<h1 id="block_1">block(<a class="headerlink" href="#block_1" title="Permanent link">&para;</a></h1>
<p>fill: luma(230),
  inset: 8pt,
  radius: 4pt,
)[令$ theta_(n+1) = theta_(n) - eta (partial cal(L)(M_theta_n，{X_i} subset E))/(partial theta_n) $
则对于大多数<span class="arithmatex"><span class="MathJax_Preview">cal(L)</span><script type="math/tex">cal(L)</script></span>和<span class="arithmatex"><span class="MathJax_Preview">M_theta</span><script type="math/tex">M_theta</script></span>，我们有
$ lim_(eta arrow 0，n arrow infinity) theta_n = theta^* $
]
这个算法的证明设计到一些统计知识，在此暂且不证明。 (如有兴趣，可以考虑: 1。 梯度在样本分布下的无偏估计是什么? 2。 考虑使用部分样本进行梯度计算时引入的噪声<span class="arithmatex"><span class="MathJax_Preview">epsilon</span><script type="math/tex">epsilon</script></span>。 这对于处于局部极小值的参数的梯度计算有什么影响?)</p>
<p>随机梯度下降法使得神经网络能够通过每次选取部分数据计算梯度，根据#text(fill: purple.darken(10%))[学习率<span class="arithmatex"><span class="MathJax_Preview">eta</span><script type="math/tex">eta</script></span>]更新</p>
<h2 id="_20">梯度的计算方法<a class="headerlink" href="#_20" title="Permanent link">&para;</a></h2>
<p>理论上，给定任何确定的网络结构，我们都可以写出梯度的解析表达。 然而当网络规模增大时，这显然是不可实现的。 因此我们需要寻找数值方法计算参数的梯度。</p>
<p>1。 数值微分法</p>
<h1 id="block_2">block(<a class="headerlink" href="#block_2" title="Permanent link">&para;</a></h1>
<p>fill: luma(230),
  inset: 8pt,
  radius: 4pt,
)[$ hat(theta_(n+1,i)) = hat(theta_(n,i)) - eta (cal(L)(M_(hat(theta_(n,i)) + epsilon)，{X_i}) - cal(L(M_(hat(theta_(n,i)) - epsilon)，{X_i})))/epsilon <span class="arithmatex"><span class="MathJax_Preview">]
该方法的时间复杂度是</span><script type="math/tex">]
该方法的时间复杂度是</script></span>cal(O)(N) times cal(O)("forward")<span class="arithmatex"><span class="MathJax_Preview">，</span><script type="math/tex">，</script></span>N<span class="arithmatex"><span class="MathJax_Preview">是参数规模。 通常来说，</span><script type="math/tex">是参数规模。 通常来说，</script></span>cal(O)("forward")$ 与参数量成近似线性关系，因此总的复杂度为<span class="arithmatex"><span class="MathJax_Preview">cal(O)(N^2)</span><script type="math/tex">cal(O)(N^2)</script></span>。 这个复杂度在参数量很大(现代深度神经网络的参数量通常在千万到百亿级别)时是不可接受的。 </p>
<p>我们注意到，在进行网络中靠近输出部分的参数的梯度计算时，两次正向传播中有大量的重复计算。 因此我们希望寻找一种能够复用计算结果的方法来降低重复计算的开销。</p>
<p>2。 反向传播
反向传播法是现有的神经网络计算梯度的最优方法。 现代深度神经网络训练框架全部使用反向传播进行梯度计算。</p>
<ul>
<li>链式法则
回顾微积分中的链式法则。 </li>
</ul>
<h1 id="block_3">block(<a class="headerlink" href="#block_3" title="Permanent link">&para;</a></h1>
<p>fill: luma(230),
  inset: 8pt,
  radius: 4pt,
)[令
<span class="arithmatex"><span class="MathJax_Preview">f: RR^a -&gt; RR^b ，g: RR^b -&gt; RR^c ，c in RR^a</span><script type="math/tex">f: RR^a -> RR^b ，g: RR^b -> RR^c ，c in RR^a</script></span>，则有
$ partial(g^((i))(arrow(f)(arrow(x))))/(partial x^((j))) = sum_(t = 1)^b (partial g<sup>((i))(f</sup>((1))(arrow(x))，dots，f^((b))(arrow(x))))/(partial f^((t))(arrow(x))) dot (partial f^((t))(arrow(x)))/(partial x^((j))) $
]
可以发现，对于任何完全由复合函数构成的函数，我们都可以将其分为两部分进行计算，这两部分都仅与构成复合函数的部分自身相关。 回顾神经网络的定义，我们发现神经网络#text(fill: purple.darken(10%))[确实由这样可导的简单部分相互连接(即复合)构成的]。 这表明我们对于神经网络的任意分割，都可以分别计算它们各自的参数的梯度，再将其按照网络结构的连接关系进行组合得到整个网络的参数的梯度。</p>
<ul>
<li>计算图
计算图是一种有向无环图，其中节点表示计算操作，边表示数据流。计算图提供了一种清晰的方式来表示复杂的计算过程，并允许方便的使用使用链式法则来计算梯度</li>
</ul>
<p>计算图由两部分组成: 节点上的运算(通常用圈表示)，以及复合关系(通常用箭头表示)。 一个神经网络唯一对应了一个计算图。</p>
<p>下面是一个典型的计算图:</p>
<h1 id="imageimgsgraphsvg">image("imgs/graph.svg")<a class="headerlink" href="#imageimgsgraphsvg" title="Permanent link">&para;</a></h1>
<p>计算图最重要的一点是实现了#text(fill: purple.darken(10%))[局部计算]: 对于每个节点，我们只需要保存正向过程的输入，并且获得下一级节点的梯度，就可以函数关于本节点的梯度。</p>
<ul>
<li>
<p>反向传播算法
反向传播算法使用计算图来组织和管理计算过程，从而有效的计算梯度。反向传播通过从计算图的输出节点开始计算出误差的梯度，并沿着计算图将其逐层传递到输入节点。这个过程被称为梯度的反向传播。通过一次从输出到输入的完整反向传播过程，我们就可以获得所有参数关于损失函数的梯度。</p>
</li>
<li>
<p>局部计算与实现的简便性
局部计算除了通过信息的复用显著降低了梯度求解的时间复杂度以外，也方便了使用现代编程语言实现神经网络。我们可以简单的将每个计算节点实例化为一个对象，这些相互不耦合的对象可以通过数据的传递完成一个完整神经网络的功能。下面给出上方计算图的实现，以及其对应的神经网络在某个训练集上的训练过程。我们假设这个神经网络的输入是a，输出为乘法节点的输出，即ab。该神经网络只含有一个参数b。我们选用的损失函数为<span class="arithmatex"><span class="MathJax_Preview">L("out", "label") = 3 times ("label"+"out")</span><script type="math/tex">L("out", "label") = 3 times ("label"+"out")</script></span>。（请自行验证该神经网络的计算过程符合上方计算图）。我们给出以下实现：
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">MulNode</span><span class="p">:</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">x</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span> <span class="kc">None</span>

  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">x</span> <span class="o">=</span> <span class="n">x</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">y</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">*</span> <span class="n">y</span>

  <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_next</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">x</span>

<span class="k">class</span> <span class="nc">AddNode</span><span class="p">:</span>
  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span>

  <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="n">d_next</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">d_next</span><span class="p">,</span> <span class="n">d_next</span>

<span class="k">class</span> <span class="nc">MyNetwork</span><span class="p">:</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">node1</span> <span class="o">=</span> <span class="n">MulNode</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">node2</span> <span class="o">=</span> <span class="n">AddNode</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">node3</span> <span class="o">=</span> <span class="n">MulNode</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">):</span>
    <span class="n">h1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">node1</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>
    <span class="n">h2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">node2</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">h1</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">node3</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">h2</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_out</span><span class="p">):</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">d_h2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">node3</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">d_out</span><span class="p">)</span>
    <span class="n">d_a</span><span class="p">,</span> <span class="n">d_h1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">node2</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">d_h2</span><span class="p">)</span>
    <span class="n">d_b</span><span class="p">,</span> <span class="n">d_c</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">node1</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">d_h1</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">MyNetwork</span><span class="p">()</span>
<span class="n">lr</span> <span class="o">=</span> <span class="mf">1e-4</span>
<span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">:</span>
  <span class="n">parameter</span> <span class="o">=</span> <span class="n">b</span>
  <span class="n">loss</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">parameter</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
  <span class="n">d_parameter</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
  <span class="n">parameter</span> <span class="o">-=</span> <span class="n">lr</span> <span class="o">*</span> <span class="n">d_parameter</span>
</code></pre></div></td></tr></table></div></p>
</li>
</ul>
<h1 id="_21">机器学习算法与神经网络的结构<a class="headerlink" href="#_21" title="Permanent link">&para;</a></h1>
<h2 id="_22">决定机器学习算法效果的评价指标<a class="headerlink" href="#_22" title="Permanent link">&para;</a></h2>
<h3 id="_23">机器学习模型的泛化问题<a class="headerlink" href="#_23" title="Permanent link">&para;</a></h3>
<p>在训练过程中，我们通过假设损失函数能够完全反映模型性能来对模型进行改进。然而在实际情况中并不如此。首先，损失函数#text(fill: purple.darken(10%))[并不一定能完全反映模型性能]，例如在生成模型中很难找到一个合适的完全反映生成质量的损失函数。其次，在神经网络学习任务中，我们通过最小化训练集上的误差（通常被称为训练误差）来训练模型。而#text(fill: purple.darken(10%))[机器学习问题和优化问题的不同在于，我们也希望泛化误差（也被称为测试误差）很低]。</p>
<p>泛化能力是指模型在新数据上的表现能力，即模型在训练集之外的数据上仍能保持良好性能的能力。一个理想的机器学习模型不仅在训练集上表现优异，还能在测试集上取得低误差。通过前面的统计学习的数据生成过程假设中的独立同分布假设，我们可以得知训练误差的期望和测试误差的期望在理论上是相同的。然而由于表示能力的不同，在训练集上的表现并不一定与测试集上相同。模型的泛化能力面临两个主要挑战：欠拟合和过拟合。</p>
<h3 id="_24">欠拟合和过拟合<a class="headerlink" href="#_24" title="Permanent link">&para;</a></h3>
<h1 id="textfill-purpledarken10underfitting">text(fill: purple.darken(10%))[欠拟合（Underfitting）是指模型在训练集上的表现不佳]，即模型无法捕捉到训练数据中的主要模式或结构。这通常是由于模型过于简单，无法有效学习数据中的复杂关系所致。例如，线性模型在处理非线性数据时往往会欠拟合。欠拟合的模型在训练集和测试集上都会有较高的误差。<a class="headerlink" href="#textfill-purpledarken10underfitting" title="Permanent link">&para;</a></h1>
<h1 id="textfill-purpledarken10overfitting">text(fill: purple.darken(10%))[过拟合（Overfitting）是指模型在训练集上表现优异]，但在测试集上的表现较差。过拟合的模型在训练过程中过于“记住”训练数据中的噪声和细节，而忽略了数据的整体结构。这导致模型在训练集上取得极低的误差，但在新数据上误差很高。过拟合通常发生在模型过于复杂或训练数据不足的情况下。<a class="headerlink" href="#textfill-purpledarken10overfitting" title="Permanent link">&para;</a></h1>
<h2 id="_25">网络结构与假设空间<a class="headerlink" href="#_25" title="Permanent link">&para;</a></h2>
<p>首先我们需要明确神经网络的结构影响了哪些因素。考虑输入n维，输出m维的神经网络。从神经网络的数学描述中可以看出，对于任意结构，任意给定参数的神经网络，其都是从<span class="arithmatex"><span class="MathJax_Preview">RR^n</span><script type="math/tex">RR^n</script></span>到<span class="arithmatex"><span class="MathJax_Preview">RR^m</span><script type="math/tex">RR^m</script></span>的函数空间的元素。于是，对于拥有k个可变参数的神经网络，其能表达的函数为<span class="arithmatex"><span class="MathJax_Preview">{F_theta|theta in RR^k}</span><script type="math/tex">{F_theta|theta in RR^k}</script></span>。这是上述函数空间的一个子集。我们发现，#text(fill: purple.darken(10%))[不同结构的神经网络实际上是上述函数空间的不同子集]。该空间称为神经网络的#text(fill: purple.darken(10%))[假设空间]。</p>
<p>通过调整神经网络的结构，我们可以调整神经网络的假设空间，</p>
<h3 id="mlp_1">MLP的表示能力与奥卡姆剃刀原则<a class="headerlink" href="#mlp_1" title="Permanent link">&para;</a></h3>
<p>为了理解神经网络结构设计的目的，我们首先引入表述MLP表达能力的一个定理：</p>
<h1 id="blockfill-luma230">block(fill: luma(230),<a class="headerlink" href="#blockfill-luma230" title="Permanent link">&para;</a></h1>
<p>inset: 8pt,
  radius: 4pt,)[
    $ forall f in cal(L)(RR^n), forall epsilon&gt;0, exists F_theta in M L P, forall x in RR^n  s.t. |F_theta (x)-f(x)|&lt;epsilon $
  ]</p>
<p>这表明参数量足够大的MLP可以以任意精度逼近任何可测函数。这是否意味着我们对于任何学习任务都可以直接选取一个足够大的MLP在训练集上进行训练呢？答案显然是否定的。#text(fill: purple.darken(10%))[机器学习任务是这样的，模型只需要表达能力足够强就可以了，而我们让模型进行学习需要考虑的就很多了，梯度下降能不能找到最优解，在训练集上训练后是否会过拟合，都需要深思熟虑。]例如，严格来说，如果我们能够完全拟合训练集分布，那么我们必然会得到一个多点离散分布。这是离散化采样带来的必然结果。但这个估计显然是不合理的，例如我们如果在图像生成任务上完全拟合训练集，那么使用训练后的模型生成图片就变成了从训练集中随机挑选一张图片。基于这一点再次强调，#text(fill: purple.darken(10%))[机器学习问题和优化问题的根本区别在于，除了希望训练误差很低，我们也希望泛化误差很低]。</p>
<p>然而从理论上来说，仅通过离散化采样，我们永远无法完整得知真实分布。#text(fill: purple.darken(10%))[奥卡姆剃刀原则（Occam’s Razor）]在逻辑学中是一条重要的指导原则。该原则陈述为如果关于同一个问题有许多种理论，每一种都能作出同样准确的预言，那么应该#text(fill: purple.darken(10%))[挑选其中最简单的]。尽管越复杂的方法通常能做出越好的预言，我们更倾向于引入外部因素更少的方法。例如给定数据集{(0,0), (1,1), (2,2)}，我们最好使用<span class="arithmatex"><span class="MathJax_Preview">y=a x</span><script type="math/tex">y=a x</script></span>作为模型对数据集进行拟合，而非<span class="arithmatex"><span class="MathJax_Preview">y = sum_(k=1)^infinity a_k x^k</span><script type="math/tex">y = sum_(k=1)^infinity a_k x^k</script></span>.</p>
<h2 id="_26">先验信息和不变性与网络结构的设计<a class="headerlink" href="#_26" title="Permanent link">&para;</a></h2>
<h3 id="_27">先验信息与网络结构<a class="headerlink" href="#_27" title="Permanent link">&para;</a></h3>
<p>根据奥卡姆剃刀原则，我们应该使得模型的假设空间#text(fill: purple.darken(10%))[在包含符合先验信息的所有可能假设的情况下尽可能小]。这表明我们需要对神经网络的结构进行合理的设计，排除掉不符合先验信息的假设，进而提高神经网络的泛化能力。</p>
<p>然而，先验信息通常很难有显式的表达，并且对于各类不同任务，先验信息也大相径庭。事实上，深度神经网络的相当一部分研究都是通过研究甚至猜测先验信息的结构，进而设计出符合特定问题的网络结构，或调整问题结构使得问题符合神经网络的假设空间。</p>
<p>我们需要牢记，机器学习的研究并非仅仅希望找到某个模型使得其具有优良的性质或强大的表达能力，而是在特定问题上优化学习模型使得其能够在该问题中达到更优良的表现。</p>







  
    
  
  


  <aside class="md-source-file">
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="最后更新">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1-2.1-2M12.5 7v5.2l4 2.4-1 1L11 13V7h1.5M11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2v1.8Z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">2024年7月13日</span>
  </span>

    
    
    
      
  
  <span class="md-source-file__fact">
    <span class="md-icon" title="贡献者">
      
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 5.5A3.5 3.5 0 0 1 15.5 9a3.5 3.5 0 0 1-3.5 3.5A3.5 3.5 0 0 1 8.5 9 3.5 3.5 0 0 1 12 5.5M5 8c.56 0 1.08.15 1.53.42-.15 1.43.27 2.85 1.13 3.96C7.16 13.34 6.16 14 5 14a3 3 0 0 1-3-3 3 3 0 0 1 3-3m14 0a3 3 0 0 1 3 3 3 3 0 0 1-3 3c-1.16 0-2.16-.66-2.66-1.62a5.536 5.536 0 0 0 1.13-3.96c.45-.27.97-.42 1.53-.42M5.5 18.25c0-2.07 2.91-3.75 6.5-3.75s6.5 1.68 6.5 3.75V20h-13v-1.75M0 20v-1.5c0-1.39 1.89-2.56 4.45-2.9-.59.68-.95 1.62-.95 2.65V20H0m24 0h-3.5v-1.75c0-1.03-.36-1.97-.95-2.65 2.56.34 4.45 1.51 4.45 2.9V20Z"/></svg>
      
    </span>
    <nav>
      
    </nav>
  </span>

    
    
  </aside>




<h2 id="__comments">评论</h2>
<!-- Insert generated snippet here -->
<script src="https://giscus.app/client.js" data-repo="sast-summer-training-2024/sast-summer-training-2024.github.io"
    data-repo-id="R_kgDOMQXCRQ" data-category="Announcements" data-category-id="DIC_kwDOMQXCRc4CggEk"
    data-mapping="pathname" data-strict="0" data-reactions-enabled="1" data-emit-metadata="0"
    data-input-position="bottom" data-theme="preferred_color_scheme" data-lang="zh-CN" crossorigin="anonymous" async>
    </script>

<!-- Synchronize Giscus theme with palette -->
<script>
    var giscus = document.querySelector("script[src*=giscus]")

    /* Set palette on initial load */
    var palette = __md_get("__palette")
    if (palette && typeof palette.color === "object") {
        var theme = palette.color.scheme === "slate" ? "dark" : "light"
        giscus.setAttribute("data-theme", theme)
    }

    /* Register event handlers after documented loaded */
    document.addEventListener("DOMContentLoaded", function () {
        var ref = document.querySelector("[data-md-component=palette]")
        ref.addEventListener("change", function () {
            var palette = __md_get("__palette")
            if (palette && typeof palette.color === "object") {
                var theme = palette.color.scheme === "slate" ? "dark" : "light"

                /* Instruct Giscus to change theme */
                var frame = document.querySelector(".giscus-frame")
                frame.contentWindow.postMessage(
                    { giscus: { setConfig: { theme } } },
                    "https://giscus.app"
                )
            }
        })
    })
</script>
                
    
        <div class="md-source-date">
            <small>
                作者: <span class='git-page-authors git-authors'></span>
            </small>
        </div>
    

              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
  回到页面顶部
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../../..", "features": ["content.code.annotate", "navigation.top", "navigation.tabs", "navigation.indexes"], "search": "../../../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}}</script>
    
    
      <script src="../../../assets/javascripts/bundle.fe8b6f2b.min.js"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      
    
  </body>
</html>